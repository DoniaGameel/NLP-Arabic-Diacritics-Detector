# -*- coding: utf-8 -*-
"""LSTM_TE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ePonThus9o0vC9WwhXg5tOl0rxIJee4g
"""

import pickle
import numpy as np

with open('drive/MyDrive/X.pickle', 'rb') as file:
    X = pickle.load(file)

with open('drive/MyDrive/Y.pickle', 'rb') as file:
    Y = pickle.load(file)

x_train = np.array(X)
y_train = np.array(Y)

from tensorflow import keras
from tensorflow.keras import regularizers
from tensorflow.keras.layers import Bidirectional, Dropout, Activation, Dense, LSTM
from tensorflow.compat.v1.keras.layers import CuDNNLSTM
from tensorflow.keras.models import Sequential

# fraction of the input to drop; helps prevent overfitting
seq_len = 25
dropout = 0.5
window_size = seq_len // 2

# Adjust input shape
input_shape = (1, 86)
num_classes =  15

model = Sequential()

model.add(LSTM(window_size, return_sequences=True, input_shape=input_shape))
model.add(Dropout(rate=dropout))
model.add(Bidirectional(LSTM((window_size * 2), return_sequences=True)))
model.add(Dropout(rate=dropout))
model.add(Bidirectional(LSTM(window_size, return_sequences=False)))
model.add(Dense(units=num_classes, activation='softmax', kernel_regularizer=regularizers.l2(0.01)))

import pickle
import tensorflow as tf
from tensorflow.keras.optimizers import Adam

batch_size = 64
y_train = tf.cast(y_train, tf.int32)
y_train = tf.one_hot(y_train, num_classes)
optimizer = Adam(learning_rate=0.001)

model.compile(loss='categorical_crossentropy', optimizer=optimizer , metrics=['accuracy'])

total = 0
step = 500
for r in range(0, 57500, step):
  print(total, r)
  with open('drive/MyDrive/trainable_embedding/te_'+str(r)+'_'+str((r+step))+'.pickle', 'rb') as file:
      X = pickle.load(file)
  l = len(X)
  x_train = np.array(X)
  x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))

  history = model.fit(
    x_train,
    y_train[total:total+l],
    epochs=10,
    batch_size=batch_size,
    shuffle=False,
    validation_split=0.1
  )

  total += l

with open('drive/MyDrive/Trainable_Embedding_Model.pickle', 'wb') as file:
  pickle.dump(model, file)

y_pred = model.predict(x_train[200:250])