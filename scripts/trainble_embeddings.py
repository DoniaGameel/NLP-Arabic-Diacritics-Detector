# -*- coding: utf-8 -*-
"""trainble_embeddings.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LIdd1s2fcs251AoV8c8SY53Gf4YKnwva
"""

import os
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Input, Embedding
from tensorflow.keras.models import Model
import numpy as np

#from google.colab import files
#uploaded = files.upload()

def get_words_embeddings(file_path, embedding_dim, batch_size):

    with open(file_path, 'r') as file:
        sentences = [line.strip().split() for line in file]

    # Tokenize the sentences
    tokenizer = Tokenizer()
    tokenizer.fit_on_texts(sentences)
    sequences = tokenizer.texts_to_sequences(sentences)

    # Pad sequences to a consistent length (optional, if needed)
    max_sequence_length = max(len(seq) for seq in sequences)
    padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')

    # Define your vocabulary size and embedding dimension
    vocab_size = len(tokenizer.word_index) + 1  # Adding 1 for the reserved index 0

    # Input layer for your data
    input_layer = Input(shape=(max_sequence_length,))

    # Embedding layer
    embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length)(input_layer)

    # Create a model with only the embedding layer
    embedding_model = Model(inputs=input_layer, outputs=embedding_layer)

    # Extract the learned embeddings for each word in the sentences
    trained_embeddings = embedding_model.predict(padded_sequences)

    return trained_embeddings

"""Extract word embeddings for training dataset"""

#In colab path
file_path = "/content/train_word_lists.txt"
#Local
#file_path = "train_word_lists.txt"
#current_file_path = os.getcwd()
# Construct the full path to the file
#file_path = os.path.join(current_file_path, file_path)

trained_embeddings = get_words_embeddings(file_path, 50, 32)

"""Extract word embeddings for validation dataset"""

#In colab path
file_path = "/content/val_word_lists.txt"
#Local
#file_path = "train_word_lists.txt"
#current_file_path = os.getcwd()
# Construct the full path to the file
#file_path = os.path.join(current_file_path, file_path)

val_trained_embeddings = get_words_embeddings(file_path, 50, 32)