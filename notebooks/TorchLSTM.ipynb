{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WR6a6DkN0d-3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch import nn\n",
        "import random as rnd\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7T_w6JbYxXy",
        "outputId": "adc7f31a-3507-4680-927a-a263f901edd0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ulSik2Sv1p1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76ad109-c11b-409f-b648-11c50163f191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ل': 0, 'م': 1, 'ي': 2, 'ع': 3, 'آ': 4, 'ه': 5, 'ك': 6, 'إ': 7, 'ت': 8, 'ؤ': 9, 'ر': 10, 'ذ': 11, 'ج': 12, 'س': 13, 'ث': 14, 'ة': 15, 'ى': 16, 'ظ': 17, 'خ': 18, 'ش': 19, 'ء': 20, 'ص': 21, 'ض': 22, 'ئ': 23, 'غ': 24, 'ز': 25, 'و': 26, 'ح': 27, 'ن': 28, 'ب': 29, 'ا': 30, 'ف': 31, 'أ': 32, 'ق': 33, 'ط': 34, 'د': 35, '#': 36}\n",
            "{'َ': 0, 'ً': 1, 'ُ': 2, 'ٌ': 3, 'ِ': 4, 'ٍ': 5, 'ْ': 6, 'ّ': 7, 'َّ': 8, 'ًّ': 9, 'ُّ': 10, 'ٌّ': 11, 'ِّ': 12, 'ٍّ': 13, '': 14, '#': 15}\n"
          ]
        }
      ],
      "source": [
        "with open('gdrive/MyDrive/arabic_letters.pickle', 'rb') as file:\n",
        "    vocab_list = list(pickle.load(file))\n",
        "\n",
        "padd_char = '#'\n",
        "\n",
        "vocab_list.append(padd_char)\n",
        "vocab = { char: i for i, char in enumerate(vocab_list) }\n",
        "\n",
        "with open('gdrive/MyDrive/diacritic2id.pickle', 'rb') as file:\n",
        "    labels_map = pickle.load(file)\n",
        "\n",
        "labels_map[padd_char] = len(labels_map)\n",
        "\n",
        "print(vocab)\n",
        "print(labels_map)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "29iM0u4-4YOV"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, x, y, pad):\n",
        "    \"\"\"\n",
        "    This is the constructor of the NERDataset\n",
        "    Inputs:\n",
        "    - x: a list of lists where each list contains the ids of the tokens\n",
        "    - y: a list of lists where each list contains the label of each token in the sentence\n",
        "    - pad: the id of the <PAD> token (to be used for padding all sentences and labels to have the same length)\n",
        "    \"\"\"\n",
        "    ##################### TODO: create two tensors one for x and the other for labels ###############################\n",
        "    # pass\n",
        "    self.x_tensor = nn.utils.rnn.pad_sequence(\n",
        "      [torch.tensor([ord(char) for char in sentence]) for sentence in x],\n",
        "      batch_first = True,\n",
        "      padding_value = ord(pad)\n",
        "    )\n",
        "    self.y_tensor = nn.utils.rnn.pad_sequence(\n",
        "      [torch.tensor(labels) for labels in y],\n",
        "      batch_first = True,\n",
        "      padding_value = labels_map[pad]\n",
        "    )\n",
        "    #################################################################################################################\n",
        "\n",
        "  def __len__(self):\n",
        "    \"\"\"\n",
        "    This function should return the length of the dataset (the number of sentences)\n",
        "    \"\"\"\n",
        "    ###################### TODO: return the length of the dataset #############################\n",
        "    # pass\n",
        "    return len(self.x_tensor)\n",
        "    ###########################################################################################\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    \"\"\"\n",
        "    This function returns a subset of the whole dataset\n",
        "    \"\"\"\n",
        "    ###################### TODO: return a tuple of x and y ###################################\n",
        "    # pass\n",
        "    return (self.x_tensor[idx], self.y_tensor[idx])\n",
        "    ##########################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataloader():\n",
        "  with open('gdrive/MyDrive/sentences_list.pickle', 'rb') as file:\n",
        "    sentences = pickle.load(file)\n",
        "\n",
        "  with open('gdrive/MyDrive/labels_list.pickle', 'rb') as file:\n",
        "    labels = pickle.load(file)\n",
        "\n",
        "  print(sentences[0])\n",
        "  print(labels[0])\n",
        "  return CustomDataset(sentences, labels, padd_char)\n"
      ],
      "metadata": {
        "id": "B17YcZ71O2TQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sz-saCtRs7Pz"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "# mini_sentences = t_sentences[0: 8]\n",
        "# mini_labels = t_labels[0: 8]\n",
        "# mini_dataset = NERDataset(mini_sentences, mini_labels, vocab['<PAD>'])\n",
        "# dummy_dataloader = torch.utils.data.DataLoader(mini_dataset, batch_size=5)\n",
        "# dg = iter(dummy_dataloader)\n",
        "# X1, Y1 = next(dg)\n",
        "# X2, Y2 = next(dg)\n",
        "# print(Y1.shape, X1.shape, Y2.shape, X2.shape)\n",
        "# print(X1[0][:], \"\\n\", Y1[0][:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xHeJcz1JuhYa"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class DiacriticLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size=35181, embedding_dim=250, hidden_size=100, num_layers=2, n_classes=len(labels_map), dropout_rate=0.5):\n",
        "        super(DiacriticLSTM, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=vocab[padd_char])\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        # self.batch_norm = nn.BatchNorm1d(hidden_size * 2)\n",
        "        self.linear = nn.Linear(hidden_size * 2, n_classes)\n",
        "\n",
        "    def forward(self, sentences):\n",
        "        embedded = self.embedding(sentences)\n",
        "        lstm_out, _ = self.lstm(embedded)\n",
        "        # lstm_out = self.batch_norm(lstm_out)\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        final_output = self.linear(lstm_out)\n",
        "        return final_output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLHx_oHpFlSX"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-yvaq8i2CCLD"
      },
      "outputs": [],
      "source": [
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "\n",
        "def train(model, train_dataset, batch_size=128, epochs=5, learning_rate=0.01):\n",
        "    \"\"\"\n",
        "    This function implements the training logic\n",
        "    Inputs:\n",
        "    - model: the model ot be trained\n",
        "    - train_dataset: the training set of type NERDataset\n",
        "    - batch_size: integer represents the number of examples per step\n",
        "    - epochs: integer represents the total number of epochs (full training pass)\n",
        "    - learning_rate: the learning rate to be used by the optimizer\n",
        "    \"\"\"\n",
        "\n",
        "    # (1) create the dataloader of the training set (make the shuffle=True)\n",
        "    train_dataloader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    # (2) make the criterion cross entropy loss\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # (3) create the optimizer (Adam)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "\n",
        "    # (4) create a learning rate scheduler\n",
        "    scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "\n",
        "    # GPU configuration\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "        criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "        total_acc_train = 0\n",
        "        total_loss_train = 0\n",
        "\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for train_input, train_label in tqdm(train_dataloader):\n",
        "\n",
        "            # (5) move the train input to the device\n",
        "            train_input = train_input.to(device)\n",
        "\n",
        "            # (6) move the train label to the device\n",
        "            train_label = train_label.to(device)\n",
        "\n",
        "            # (7) do the forward pass\n",
        "            output = model(train_input)\n",
        "\n",
        "            # (8) loss calculation (you need to think in this part how to calculate the loss correctly)\n",
        "            batch_loss = criterion(output.view(-1, output.shape[-1]), train_label.view(-1))\n",
        "\n",
        "            # (9) append the batch loss to the total_loss_train\n",
        "            total_loss_train += batch_loss.item()\n",
        "\n",
        "            # (10) calculate the batch accuracy (just add the number of correct predictions)\n",
        "            acc = (output.argmax(dim=-1) == train_label).sum().item()\n",
        "            total_acc_train += acc\n",
        "\n",
        "            # (11) zero your gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # (12) do the backward pass\n",
        "            batch_loss.backward()\n",
        "\n",
        "            # (13) update the weights with your optimizer\n",
        "            optimizer.step()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "\n",
        "        # (14) step the learning rate scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # epoch loss\n",
        "        epoch_loss = total_loss_train / len(train_dataset)\n",
        "\n",
        "        # (15) calculate the accuracy\n",
        "        epoch_acc = total_acc_train / (len(train_dataset) * train_dataset[0][0].shape[0])\n",
        "\n",
        "        print(\n",
        "            f'Epochs: {epoch_num + 1} | Train Loss: {epoch_loss} \\\n",
        "            | Train Accuracy: {epoch_acc}\\n')\n",
        "\n",
        "    ##############################################################################################################\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3BI7_ANkLf7G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b9e3c5-d5e5-4618-c51e-c1791bbcc91d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "قوله أو قطع الأول يده إلخ قال الزركشي\n",
            "[0, 6, 2, 2, 14, 0, 6, 14, 0, 0, 0, 14, 14, 6, 0, 8, 2, 14, 0, 0, 2, 14, 14, 0, 6, 14, 0, 14, 0, 14, 14, 14, 8, 6, 0, 4, 10]\n"
          ]
        }
      ],
      "source": [
        "# train_dataset = NERDataset(t_sentences, t_labels, vocab['<PAD>'])\n",
        "# val_dataset = NERDataset(v_sentences, v_labels, vocab['<PAD>'])\n",
        "# test_dataset = NERDataset(test_sentences, test_labels, vocab['<PAD>'])\n",
        "train_dataset = prepare_dataloader()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = DiacriticLSTM()"
      ],
      "metadata": {
        "id": "EtrCRJXZExYQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "yX5wqW2FIqUI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMXjDv51LU6k",
        "outputId": "5b509e5f-e568-43a0-9a56-a2bc2059557e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 402/402 [02:41<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | Train Loss: 0.0005076735432081662             | Train Accuracy: 0.9786629038652119\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 402/402 [02:49<00:00,  2.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 2 | Train Loss: 0.00022392445156034434             | Train Accuracy: 0.9907587807969958\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 402/402 [02:49<00:00,  2.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 3 | Train Loss: 0.00019395484157345728             | Train Accuracy: 0.9920345932780432\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 402/402 [02:49<00:00,  2.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 4 | Train Loss: 0.00017911656285956592             | Train Accuracy: 0.9926489587518443\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 402/402 [02:49<00:00,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 5 | Train Loss: 0.00016922134767650423             | Train Accuracy: 0.9930587743778897\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train(model, train_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AurZi1QUxC00"
      },
      "source": [
        "#### Expected train accuracy after 5 epochs to be above 0.99"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWJNO6mUXPRI"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Gz5mxUAJM1xS"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_dataset, batch_size=256):\n",
        "  \"\"\"\n",
        "  This function takes a NER model and evaluates its performance (accuracy) on a test data\n",
        "  Inputs:\n",
        "  - model: a NER model\n",
        "  - test_dataset: dataset of type NERDataset\n",
        "  \"\"\"\n",
        "  ########################### TODO: Replace the Nones in the following code ##########################\n",
        "\n",
        "  # (1) create the test data loader\n",
        "  test_dataloader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = False\n",
        "  )\n",
        "\n",
        "  # GPU Configuration\n",
        "  use_cuda = torch.cuda.is_available()\n",
        "  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "  if use_cuda:\n",
        "    model = model.cuda()\n",
        "\n",
        "  total_acc_test = 0\n",
        "\n",
        "  # (2) disable gradients\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for test_input, test_label in tqdm(test_dataloader):\n",
        "      # (3) move the test input to the device\n",
        "      test_label = test_label.to(device)\n",
        "\n",
        "      # (4) move the test label to the device\n",
        "      test_input = test_input.to(device)\n",
        "\n",
        "      # (5) do the forward pass\n",
        "      output = model(test_input)\n",
        "\n",
        "      # accuracy calculation (just add the correct predicted items to total_acc_test)\n",
        "      acc = (torch.argmax(output, dim=-1) == test_label).sum().item()\n",
        "      total_acc_test += acc\n",
        "\n",
        "    # (6) calculate the over all accuracy\n",
        "    total_acc_test /= (len(test_dataset) * test_dataset[0][0].shape[0])\n",
        "  ##################################################################################################\n",
        "\n",
        "\n",
        "  print(f'\\nTest Accuracy: {total_acc_test}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('gdrive/MyDrive/val_sentences_list.pickle', 'rb') as file:\n",
        "  test_sentences = pickle.load(file)\n",
        "\n",
        "with open('gdrive/MyDrive/val_labels_list.pickle', 'rb') as file:\n",
        "  test_labels = pickle.load(file)\n",
        "\n",
        "print(test_sentences[0])\n",
        "print(test_labels[0])\n",
        "test_dataset = CustomDataset(test_sentences, test_labels, padd_char)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbvIFirvlGZc",
        "outputId": "680706e2-25f3-442d-86f6-10489c79de5b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "قوله ولا تكره ضيافته\n",
            "[0, 6, 2, 2, 14, 0, 0, 14, 14, 2, 6, 0, 2, 14, 4, 0, 14, 0, 2, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FD8JNcHWmMY",
        "outputId": "3b41f01a-73d9-43f8-d497-21431e5acd36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:02<00:00,  4.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy: 0.9907391194194031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate(model, test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "0UmaD_BXpK5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_dataset, batch_size=256):\n",
        "  \"\"\"\n",
        "  This function takes a NER model and evaluates its performance (accuracy) on a test data\n",
        "  Inputs:\n",
        "  - model: a NER model\n",
        "  - test_dataset: dataset of type NERDataset\n",
        "  \"\"\"\n",
        "  ########################### TODO: Replace the Nones in the following code ##########################\n",
        "\n",
        "  # (1) create the test data loader\n",
        "  test_dataloader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = False\n",
        "  )\n",
        "\n",
        "  # GPU Configuration\n",
        "  use_cuda = torch.cuda.is_available()\n",
        "  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "  if use_cuda:\n",
        "    model = model.cuda()\n",
        "\n",
        "  pred = []\n",
        "\n",
        "  # (2) disable gradients\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for test_input, test_label in tqdm(test_dataloader):\n",
        "      # (3) move the test input to the device\n",
        "      test_label = test_label.to(device)\n",
        "\n",
        "      # (4) move the test label to the device\n",
        "      test_input = test_input.to(device)\n",
        "      # print('INPUT:', test_input)\n",
        "      # (5) do the forward pass\n",
        "      output = model(test_input)\n",
        "      # print('OUTPUT:', output)\n",
        "      p = torch.argmax(output, dim=-1)\n",
        "      # print('PREDECTION:', p)\n",
        "      pred.append(p)\n",
        "\n",
        "  return pred"
      ],
      "metadata": {
        "id": "hguDK3xSpDf4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('gdrive/MyDrive/test_sentences_list_1.pickle', 'rb') as file:\n",
        "  test_sentences_leaderboard = pickle.load(file)\n",
        "\n",
        "with open('gdrive/MyDrive/test_labels_list_1.pickle', 'rb') as file:\n",
        "  test_labels_leaderboard = pickle.load(file)\n",
        "\n",
        "print(test_sentences_leaderboard[0])\n",
        "print(test_labels_leaderboard[0])\n",
        "test_dataset_leaderboard = CustomDataset(test_sentences_leaderboard, test_labels_leaderboard, padd_char)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhPWRz5VpldU",
        "outputId": "0bc25fae-f72e-4154-af56-62c4fcb8ecfc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "صوتقديمالحلقأوالإفاضةعلىالرميشهذابالجرمعطوفعلىمايوجبالدموهوقولهفيمامركتأخيرالحلقلبلدهوالمعنىأنهإذاقدمالحلقعلىرميجمرةالعقبةفإنهتلزمهالفديةلوقوعهقبلشيءمنالتحللكمافيالمدونةلاهديكمايعطيهكلامالمؤلفلأنالدمإنماينصرفللهديفإذارمىالعقبةأمرالموسىعلىرأسهلأنالحلقالأولوقعقبلمحلهوكذلكيلزمهالهديإذاقدمطوافالإفاضةعلىرميجمرةالعقبةمعالإجزاءعلىالمشهوروكلامالمؤلفيصدقبتقديمالإفاضةعلىيومالنحروليسبمرادلأنفعلالإفاضةقبليومالنحركلافعللأنهفعللهاقبلوقتهاولوقدمكلامنالإفاضةوالحلقعلىالرميلوجبفيهمافديةوهديثمإنالترتيببينكلمنهماوبينالرميواجبإذلوكانمستحبالماوجبفيهشيءوهوظاهرلأنالرميهوالتحللالأصغرصلاإنخالففيغيرشأيلاإنخالفعمداأونسياناأوجهلافيغيرماتقدمبأنحلققبلأنيذبحأونحرقبلأنيرميأوقدمالإفاضةعلىالنحرأوعلىالحلقأوعليهمافإنهلادم\n",
            "[14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = test(model, test_dataset_leaderboard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwPw9FDvqh4g",
        "outputId": "27f44de5-de5f-40ce-b4b6-ac2e798dbc89"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 116.61it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(pred[0][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLoy3YXBrJms",
        "outputId": "554e6d92-446e-4b5d-9715-463d44b15aad"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_pred = [batch.cpu().detach().numpy() for batch in pred]\n",
        "final_pred = np.concatenate(numpy_pred)"
      ],
      "metadata": {
        "id": "09fAL8PGty8M"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_pred.shape)\n",
        "total = 0\n",
        "for sentence in final_pred:\n",
        "  for char in sentence:\n",
        "    if char != 15:\n",
        "      total += 1\n",
        "print(total)\n",
        "print(len(test_sentences_leaderboard[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_RWJtrMutfE",
        "outputId": "e2ab17c2-190b-4128-e795-506deeec2164"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 925)\n",
            "34074\n",
            "694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "index = 0\n",
        "\n",
        "with open('test_prediction.csv', 'a', newline='') as csvfile:\n",
        "  fieldnames = ['ID', 'label']\n",
        "  writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "  if csvfile.tell() == 0:\n",
        "      writer.writeheader()\n",
        "\n",
        "  for i, sentence in enumerate(test_sentences_leaderboard):\n",
        "    for j, char in enumerate(sentence):\n",
        "      if char != ' ':\n",
        "        writer.writerow({'ID': index, 'label': final_pred[i][j]})\n",
        "        index += 1"
      ],
      "metadata": {
        "id": "PDpMD0oNv_9M"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrVVsazG1GUs",
        "outputId": "4d12da9b-9632-43d6-8bbb-d62c0d4a5715"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kILSh_TiLV-t"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}